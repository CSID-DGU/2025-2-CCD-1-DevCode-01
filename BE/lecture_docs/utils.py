import base64
import os
import fitz
from openai import OpenAI
from pdfminer.high_level import extract_pages
from pdfminer.layout import LTTextContainer
from django.core.files.base import ContentFile
from classes.utils import text_to_speech
from lecture_docs.models import Doc, Page
from dotenv import load_dotenv

def pdf_to_image(page, title, page_num):

    pix = page.get_pixmap(dpi=150)
    img_bytes = pix.tobytes("png")
    image_file = ContentFile(img_bytes, name=f"{title}_page{page_num}.png")
    return image_file

load_dotenv() 
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

PROMPT_TEMPLATE = """
ë„ˆëŠ” ì‹œê°ì¥ì• ì¸ì´ ì ‘ê·¼ ê°€ëŠ¥í•œ í•™ìŠµìë£Œë¥¼ ì œì‘í•˜ëŠ” ë³´ì¡°ìì•¼. 
ë‹¤ìŒì€ ê°•ì˜ìë£Œë¥¼ ì´ë¯¸ì§€íŒŒì¼ë¡œ ë§Œë“¤ì–´ë‚¸ ê±°ì•¼. 
ì´ ì‚¬ì§„ì€ PDFì˜ ê° í˜ì´ì§€ì—ì„œ ì¶”ì¶œëœ ê±°ì•¼. 

ê° í˜ì´ì§€ë¥¼ ë‹¤ìŒ êµ¬ì¡°ë¡œ ê°€ê³µí•´ì¤˜:
1. ğŸ“Œ ì œëª©(ìˆë‹¤ë©´)
2. ğŸ“„ ë³¸ë¬¸ í…ìŠ¤íŠ¸: ë¬¸ë‹¨ êµ¬ë¶„ì„ ìœ ì§€í•˜ë©° ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬, ì‚¬ì§„ ì™¸ì˜ ë‚´ìš©ì€ ì„¤ëª…í•˜ì§€ë§ˆ
3. ğŸ–¼ï¸ ì´ë¯¸ì§€/ë„ì‹ ì„¤ëª…(ìˆë‹¤ë©´): ë³´ì´ì§€ ì•Šì•„ë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì´ë¯¸ì§€ ë‚´ìš©ì„ ë§ë¡œ ì„¤ëª…, ë³¸ë¬¸ê³¼ ì—°ê´€ì§€ì–´ì„œ ì„¤ëª…, ìˆ˜ì—… ë‚´ìš©ê³¼ ê´€ë ¨ì—†ëŠ” ë°°ê²½ì´ë¯¸ì§€, ë¡œê³ ê°™ì€ê±´ ì„¤ëª…ìƒëµ
4. ğŸ“Š í‘œê°€ ìˆë‹¤ë©´: í‘œ ë‚´ìš©ì„ êµ¬ì¡°ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ì¬êµ¬ì„±, ë³¸ë¬¸ê³¼ ì—°ê´€ì§€ì–´ì„œ ì„¤ëª…
"""

def image_to_base64(image_path):
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def page_ocr(page: Page):
    image_b64 = image_to_base64(page.image.path)

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": PROMPT_TEMPLATE},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì¤˜."},
                    {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_b64}"}}
                ]
            },
        ],
        temperature=0.3,
    )

    result = response.choices[0].message.content.strip()
    page.ocr = result
    page.save(update_fields=["ocr"])
    return result

def summarize_stt(doc_id: int) -> tuple[str, str]:
    """
    1. Doc IDë¡œ ëª¨ë“  Page.speechesì˜ STT í…ìŠ¤íŠ¸ ë³‘í•©
    2. ê°•ì˜ëª…, êµì•ˆëª…ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    3. Gemini ëª¨ë¸ì„ ì´ìš©í•´ 1000ì ì´ë‚´ ìš”ì•½ ìƒì„±
    4. Google TTS ë³€í™˜ + S3 ì—…ë¡œë“œ
    5. ìš”ì•½ë¬¸ê³¼ TTS URL ë°˜í™˜
    """
    
    # 1ï¸âƒ£ êµì•ˆ ë° ì—°ê´€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    doc = Doc.objects.select_related("lecture").prefetch_related("pages__speeches").get(id=doc_id)
    lecture_title = doc.lecture.title if doc.lecture else "ê°•ì˜"
    doc_title = doc.title

    # 2ï¸âƒ£ ëª¨ë“  í˜ì´ì§€ì˜ STT í…ìŠ¤íŠ¸ ë³‘í•©
    stt_texts = [
        speech.stt.strip()
        for page in doc.pages.all()
        for speech in page.speeches.all()
        if speech.stt and speech.stt.strip()
    ]
    if not stt_texts:
        raise ValueError("ìš”ì•½í•  STT ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    combined_stt = "\n".join(stt_texts)

    # 3ï¸âƒ£ Gemini í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = f"""
    ë„ˆëŠ” '{lecture_title}' ê°•ì˜ì˜ '{doc_title}' êµì•ˆì— ëŒ€í•œ ì „ë¬¸ê°€ì•¼.
    ì•„ë˜ëŠ” ê°•ì˜ ì¤‘ êµìˆ˜ë‹˜ì´ ì‹¤ì œë¡œ ë§í•œ ë‚´ìš©ì´ì•¼.
    ì´ ë‚´ìš©ì„ ì „ì²´ì ìœ¼ë¡œ ì½ê³ , 1000ì ì´ë‚´ë¡œ ìš”ì•½í•´ì¤˜.

    ë‹¨, ì˜¤íƒˆìë‚˜ ì¼ë¶€ ëˆ„ë½ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì˜ë¯¸ë¥¼ ì˜¬ë°”ë¥´ê²Œ í•´ì„í•˜ê³ ,
    ì›ë¬¸ì— ì—†ëŠ” ìƒˆë¡œìš´ ì‚¬ì‹¤ì€ ì¶”ê°€í•˜ì§€ ë§ê³ ,
    ì¤‘ë³µëœ ì„¤ëª…ì€ ìƒëµí•˜ê³ ,
    ì¤‘ìš”í•˜ê³  í•µì‹¬ì ì¸ ê°œë… ìœ„ì£¼ë¡œ ì •ë¦¬í•´.
    ---
    {combined_stt}
    ---
    ìš”ì•½ë¬¸:
    """

    summary_text = summarize(prompt)

    # Google TTS ë³€í™˜ + S3 ì—…ë¡œë“œ
    try:
        tts_url = text_to_speech(summary_text, s3_folder="tts/stt_summary/")
    except Exception as e:
        raise RuntimeError(f"TTS ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    return summary_text, tts_url

# def summarize_doc(doc_id: int) -> tuple[str, str]:
#     # 1ï¸âƒ£ êµì•ˆ ë° ì—°ê´€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
#     doc = Doc.objects.select_related("lecture").prefetch_related("pages__speeches").get(id=doc_id)
#     lecture_title = doc.lecture.title if doc.lecture else "ê°•ì˜"
#     doc_title = doc.title

#     # 2ï¸âƒ£ ëª¨ë“  í˜ì´ì§€ì˜ ocr í…ìŠ¤íŠ¸ ë³‘í•©
#     ocr_texts = [
#         page.ocr.strip()
#         for page in doc.pages.all()
#         if page.ocr and page.ocr.strip()
#     ]

#     if not ocr_texts:
#         raise ValueError("ìš”ì•½í•  OCR ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

#     combined_ocr = "\n".join(ocr_texts)

#     # 3ï¸âƒ£ Gemini í”„ë¡¬í”„íŠ¸ ìƒì„±
#     prompt = f"""
#     ë„ˆëŠ” '{lecture_title}' ê°•ì˜ì˜ '{doc_title}' êµì•ˆì— ëŒ€í•œ ì „ë¬¸ê°€ì•¼.
#     ì•„ë˜ëŠ” ê°•ì˜ êµì•ˆì˜ OCR ì¸ì‹ ê²°ê³¼ì•¼.
#     ì´ ë‚´ìš©ì„ ì „ì²´ì ìœ¼ë¡œ ì½ê³ , 200ì ì´ë‚´ë¡œ ìš”ì•½í•´ì¤˜.

#     ë‹¨, ì˜¤íƒˆìë‚˜ ì¼ë¶€ ëˆ„ë½ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì˜ë¯¸ë¥¼ ì˜¬ë°”ë¥´ê²Œ í•´ì„í•˜ê³ ,
#     ì›ë¬¸ì— ì—†ëŠ” ìƒˆë¡œìš´ ì‚¬ì‹¤ì€ ì¶”ê°€í•˜ì§€ ë§ê³ ,
#     ì¤‘ë³µëœ ì„¤ëª…ì€ ìƒëµí•˜ê³ ,
#     ì¤‘ìš”í•˜ê³  í•µì‹¬ì ì¸ ê°œë… ìœ„ì£¼ë¡œ ì •ë¦¬í•´.
#     ---
#     {combined_ocr}
#     ---
#     ìš”ì•½ë¬¸:
#     """

#     return summarize(prompt)

# def summarize(prompt: str) -> str:
#     """
#     Gemini í˜¸ì¶œ ìš”ì•½ë³¸ ìƒì„± í•¨ìˆ˜
#     í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ì„œ ìš”ì•½ë¬¸ ë°˜í™˜
#     """

#     # Gemini ëª¨ë¸ í˜¸ì¶œ
#     try:
#         model = generative_models.GenerativeModel("gemini-2.5-flash")
#         response = model.generate_content(prompt)

#         if not response or not getattr(response, "text", "").strip():
#             raise ValueError("Gemini ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        
#         summary_text = response.text.strip()

#     except Exception as e:
#         raise RuntimeError(f"Gemini ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

#     return summary_text

