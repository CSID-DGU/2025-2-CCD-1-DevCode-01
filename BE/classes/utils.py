import re
import tempfile
import wave
from bs4 import BeautifulSoup
from google.cloud import speech, storage
from google.cloud import texttospeech, translate_v2 as translate
import boto3
from django.conf import settings
import io, os
import uuid
from datetime import datetime, timedelta
from groq import Groq
import markdown
import numpy as np

from users.models import User

symbol_map = {
    "!": "ëŠë‚Œí‘œ",
    "@": "ì•³",
    "#": "ìƒµ",
    "$": "ë‹¬ëŸ¬",
    "%": "í¼ì„¼íŠ¸",
    "^": "ìºëŸ¿",
    "&": "ì•¤ë“œ",
    "*": "ì• ìŠ¤í„°ë¦¬ìŠ¤í¬",
    "(": "ê´„í˜¸ ì—´ê³ ",
    ")": "ê´„í˜¸ ë‹«ê³ ",
    "-": "í•˜ì´í”ˆ",
    "_": "ì–¸ë”ìŠ¤ì½”ì–´",
    "=": "ì´í€„",
    "+": "í”ŒëŸ¬ìŠ¤",
    "[": "ëŒ€ê´„í˜¸ ì—´ê³ ",
    "]": "ëŒ€ê´„í˜¸ ë‹«ê³ ",
    "{": "ì¤‘ê´„í˜¸ ì—´ê³ ",
    "}": "ì¤‘ê´„í˜¸ ë‹«ê³ ",
    "\\": "ë°±ìŠ¬ë˜ì‹œ",
    "|": "íŒŒì´í”„",
    ";": "ì„¸ë¯¸ì½œë¡ ",
    ":": "ì½œë¡ ",
    "'": "ì‘ì€ë”°ì˜´í‘œ",
    '"': "í°ë”°ì˜´í‘œ",
    ",": "ì½¤ë§ˆ",
    ".": "ì ",
    "/": "ìŠ¬ë˜ì‹œ",
    "?": "ë¬¼ìŒí‘œ",
    "<": "êº¾ì‡  ì—´ê³ ",
    ">": "êº¾ì‡  ë‹«ê³ ",
    "~": "í‹¸ë‹¤",
    "`": "ë°±í‹±",
    "\t": "ë“¤ì—¬ì“°ê¸°",
}

symbol_pattern = re.compile("|".join(re.escape(k) for k in symbol_map.keys()))
code_pattern = re.compile(r"<ì½”ë“œ>(.*?)</ì½”ë“œ>", re.DOTALL)
math_pattern = re.compile(r"<ìˆ˜ì‹>(.*?)</ìˆ˜ì‹>", re.DOTALL)

client = Groq(api_key=settings.GROQ_API_KEY)

def upload_to_gcs(file_bytes: bytes, filename: str, bucket_name: str) -> str:
    """GCS ë²„í‚·ì— íŒŒì¼ ì—…ë¡œë“œ í›„ URI ë°˜í™˜"""
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(f"stt/{filename}")
    blob.upload_from_string(file_bytes)
    return f"gs://{bucket_name}/stt/{filename}"

def split_audio_on_silence(wav_bytes: bytes, silence_threshold=150, min_silence_len=2000):
    """
    WAV íŒŒì¼ì„ ë¬´ìŒ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜
    - silence_threshold: ë¬´ìŒ íŒë‹¨ ê¸°ì¤€ (ìƒ˜í”Œ ì§„í­)
    - min_silence_len: ë¬´ìŒ ê¸¸ì´ ê¸°ì¤€ (ms)
    """
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(wav_bytes)
        tmp.flush()
        wav_path = tmp.name

    with wave.open(wav_path, "rb") as wf:
        rate = wf.getframerate()
        channels = wf.getnchannels()
        sampwidth = wf.getsampwidth()
        n_frames = wf.getnframes()
        frames = wf.readframes(n_frames)

    # 16-bit PCMë§Œ ì§€ì›(ì¼ë°˜ì ). ê·¸ ì™¸ëŠ” ì•ˆì „í•˜ê²Œ ì „ì²´ë¥¼ í•˜ë‚˜ë¡œ ë°˜í™˜.
    if sampwidth != 2:
        return [wav_path], rate  # ë¶„í•  ë¶ˆê°€ â†’ í†µì§œë¡œ ì²˜ë¦¬

    audio = np.frombuffer(frames, dtype=np.int16)
    if channels > 1:
        audio = audio.reshape(-1, channels)
        # ìŠ¤í…Œë ˆì˜¤ë©´ ë‘ ì±„ë„ì˜ í‰ê·  ì ˆëŒ€ê°’ìœ¼ë¡œ ë¬´ìŒ íŒë‹¨
        mono = audio.mean(axis=1).astype(np.int16)
    else:
        mono = audio

    abs_audio = np.abs(mono).astype(np.int32)
    silence_len = int((min_silence_len / 1000.0) * rate)

    silent_ranges = []
    start = None
    for i, v in enumerate(abs_audio):
        if v < silence_threshold:
            if start is None:
                start = i
        else:
            if start is not None and (i - start) >= silence_len:
                silent_ranges.append((start, i))
            start = None
    # ë¶„í•  í¬ì¸íŠ¸ êµ¬ì„±
    split_points = [0] + [end for (_, end) in silent_ranges] + [len(mono)]

    chunks = []
    for i in range(len(split_points) - 1):
        s, e = split_points[i], split_points[i+1]
        if e - s < int(0.5 * rate):  # 0.5ì´ˆ ë¯¸ë§Œ chunkëŠ” ìŠ¤í‚µ
            continue
        # ì›ë³¸ ì±„ë„ìˆ˜ ìœ ì§€í•´ì„œ íŒŒì¼ë¡œ ë‹¤ì‹œ ì”€
        chunk_frames = audio[s*channels:e*channels] if channels > 1 else audio[s:e]
        out = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        with wave.open(out.name, "wb") as ow:
            ow.setnchannels(channels)
            ow.setsampwidth(sampwidth)
            ow.setframerate(rate)
            ow.writeframes(chunk_frames.tobytes())
        chunks.append(out.name)

    # ë¶„í• ì´ ì „í˜€ ì•ˆ ë˜ì—ˆìœ¼ë©´ ì›ë³¸ wav ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if not chunks:
        chunks = [wav_path]
    else:
        # ì›ë³¸ tempëŠ” ë¶„í• ì´ ëìœ¼ë©´ ì œê±°
        os.remove(wav_path)

    return chunks, rate

def speech_to_text(audio_path) -> tuple[str, list]:
    client = speech.SpeechClient(transport="rest")

    with open(audio_path, "rb") as f:
        content = f.read()

    if len(content) < 10000:  
        raise ValueError("ìŒì„± íŒŒì¼ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. 1ì´ˆ ì´ìƒ ê¸¸ì´ì˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

    filename = audio_path.lower()
    if filename.endswith(".wav"):
        format_type = "wav"
        encoding = speech.RecognitionConfig.AudioEncoding.LINEAR16
    else:
        raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í˜•ì‹ì…ë‹ˆë‹¤. (wavë§Œ ê°€ëŠ¥)")

    chunks, rate = split_audio_on_silence(content)

    config = speech.RecognitionConfig(
        encoding=encoding,
        language_code="ko-KR",
        sample_rate_hertz=rate,
        enable_separate_recognition_per_channel=False,
        model="latest_long",
        use_enhanced=True,
        enable_automatic_punctuation=True,
        enable_word_time_offsets=True
    )

    transcript = ""
    stt_words = []
    offset = 0.0

    for chunk in chunks:
        with open(chunk, "rb") as f:
            chunk_bytes = f.read()

        if len(chunk_bytes) < 1024 * 1024:
            audio = speech.RecognitionAudio(content=chunk_bytes)
            response = client.recognize(config=config, audio=audio)
        else:
            gcs_uri = upload_to_gcs(
                chunk_bytes,
                f"{uuid.uuid4()}.{format_type}",
                settings.GCP_BUCKET_NAME
            )
            audio = speech.RecognitionAudio(uri=gcs_uri)
            operation = client.long_running_recognize(config=config, audio=audio)
            response = operation.result(timeout=900)

        if response.results:
            for result in response.results:
                alt = result.alternatives[0]
                transcript += alt.transcript.strip() + " "
                for w in alt.words:
                    stt_words.append({
                        "word": w.word,
                        "start": w.start_time.total_seconds() + offset,
                        "end": w.end_time.total_seconds() + offset,
                    })

        os.remove(chunk)

    transcript = transcript.strip()
    if not transcript:
        raise ValueError("ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    return transcript, stt_words


def extract_text(stt_words, relative_time, user: User):
    for w in stt_words:
        if w["start"] <= relative_time <= w["end"]:
            return find_full_text(stt_words, w, user)
    return None

def find_full_text(stt_words, target_word, user: User):
    idx = stt_words.index(target_word)

    # ì˜¤ë¥¸ìª½ìœ¼ë¡œ wpsì´ˆ êµ¬ê°„ë§Œ ì¶”ì¶œ
    sentence_words = [target_word["word"]]
    start_time = target_word["start"]

    if user.rate == "ëŠë¦¼":
        wps = 4.0
    elif user.rate == "ë¹ ë¦„":
        wps = 8.0
    else:
        wps = 6.0  # ê¸°ë³¸ê°’
    
    for w in stt_words[idx+1:]:
        if w["end"] - start_time > wps: # ì‹œì‘ ë‹¨ì–´ ê¸°ì¤€ìœ¼ë¡œ wpsì´ˆ
            break
        sentence_words.append(w["word"])
    
    # ë‹¨ì–´ ê²°í•© (â– ì œê±°í•˜ê³  ê³µë°± ì²˜ë¦¬)
    return "".join([w.replace("â–", " ") for w in sentence_words]).strip()

# ì½”ë“œ ì „ì²˜ë¦¬
def preprocess_code(code_text: str) -> str:
    lines = code_text.split("\n")
    processed_lines = []

    for line in lines:
        # 1) ì•ìª½ ê³µë°± ê°œìˆ˜ â†’ ë“¤ì—¬ì“°ê¸°
        leading_spaces = len(line) - len(line.lstrip(' '))
        total_indent = (leading_spaces // 4)
        indent_text = " ".join(["ë“¤ì—¬ì“°ê¸°"] * total_indent) + " " if total_indent > 0 else ""

        # 2) ë‚´ìš© ë¶€ë¶„
        content = line.lstrip(' ')

        # 3) íŠ¹ìˆ˜ë¬¸ì ì „ì²˜ë¦¬
        def replace_symbol(match):
            return f" {symbol_map[match.group(0)]} "

        content = symbol_pattern.sub(replace_symbol, content)

        # 4) ê²°ê³¼ í•©ì¹˜ê¸°
        processed_lines.append(indent_text + content.strip())

    # 5) ì¤„ë°”ê¿ˆ ì²˜ë¦¬
    return " ì¤„ë°”ê¿ˆ ".join(processed_lines)

def preprocess_text(processed_math):
    
    def replace_code(match):
        code_text = match.group(1)
        # ì½”ë“œ ì „ì²˜ë¦¬
        processed_code = preprocess_code(code_text)
        return processed_code
    
    def translate_math(match):
        english_math = match.group(1)
        # ìˆ˜ì‹ ë²ˆì—­
        korean_math = translate(english_math)
        return korean_math

    # ìµœì¢… ì „ì²˜ë¦¬ í…ìŠ¤íŠ¸
    processed_text = code_pattern.sub(replace_code, processed_math)
    processed_text = math_pattern.sub(translate_math, processed_text)

    return processed_text

def translate(text: str) -> str:
    prompt = f"""
    ë„ˆëŠ” ì˜ì–´ ìˆ˜ì‹ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ê°€ì´ë‹¤.
    ì•„ë˜ëŠ” ì˜ì–´ë¡œ í‘œí˜„ëœ ìˆ˜ì‹ì´ë‹¤:
    ---
    {text}
    ---
    
    ì´ ìˆ˜ì‹ì„ í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•œë‹¤.
    ë²ˆì—­ ê·œì¹™ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:

    1) ìˆ˜ì‹ì˜ ê¸°í˜¸, êµ¬ì¡°, ê´€ê³„ë¥¼ í•œêµ­ì–´ë¡œ ì •í™•íˆ í‘œí˜„í•œë‹¤.
    2) ìˆ˜ì‹ì„ ì„¤ëª…í•˜ê±°ë‚˜ í•´ì„í•˜ì§€ ì•Šê³ , ì œê³µëœ ìˆ˜ì‹ ìì²´ë§Œ ë²ˆì—­í•œë‹¤.
    3) '~ì…ë‹ˆë‹¤', '~í•©ë‹ˆë‹¤', '~ë©ë‹ˆë‹¤' ë“± ë¬¸ì–´ì²´ ì¢…ê²°ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.
    4) ì¶œë ¥ì€ ë²ˆì—­ëœ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë§Œ ì œê³µí•œë‹¤.

    ë²ˆì—­ë¬¸:
    """

    response = client.chat.completions.create(
        model="openai/gpt-oss-20b",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.1,
    )
    
    result = response.choices[0].message.content.strip()
    
    return result

def markdown_to_text(md_text: str) -> str:
    if not md_text or md_text.strip() == "":
        raise ValueError("ë³€í™˜í•  ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    html = markdown.markdown(md_text)

    soup = BeautifulSoup(html, "lxml")
    text = soup.get_text(separator="\n")

    text = re.sub(r'\n\s*\n', '\n', text).strip()

    return text


def text_to_speech(text: str, user: User, s3_folder: str = "tts/") -> str:
    
    if not text or text.strip() == "":
        raise ValueError("TTS ë³€í™˜í•  í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    client = texttospeech.TextToSpeechClient(transport="rest")

    synthesis_input = texttospeech.SynthesisInput(text=text)
    
    voice_map = {
        "female": "ko-KR-Neural2-A",
        "male": "ko-KR-Neural2-C",
    }

    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        speaking_rate=1.0,
    )

    s3_urls = {}

    for gender, name in voice_map.items():
        voice_config = texttospeech.VoiceSelectionParams(
            language_code="ko-KR",
            name=name,
        )

        response = client.synthesize_speech(
            input=synthesis_input,
            voice=voice_config,
            audio_config=audio_config
        )

        if not response.audio_content:
            raise ValueError("TTS ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    
        s3 = boto3.client(
            's3',
            aws_access_key_id=settings.AWS_ACCESS_KEY_ID,
            aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,
            region_name='ap-northeast-2'
        )

        bucket_name = settings.AWS_BUCKET_NAME
        filename = f"{uuid.uuid4()}.mp3"
        s3_key = f"{s3_folder}{filename}"

        # BytesIOë¡œ ë©”ëª¨ë¦¬ ë‚´ì—ì„œ ì§ì ‘ ì—…ë¡œë“œ
        s3.upload_fileobj(
            io.BytesIO(response.audio_content),
            bucket_name,
            s3_key,
            ExtraArgs={'ContentType': 'audio/mpeg'}
        )

        s3_url = f"{settings.AWS_S3_BASE_URL}/{s3_key}"
        s3_urls[gender] = s3_url

    return s3_urls

def text_to_speech_local(text: str, voice: str, rate: str) -> str:
    """
    Google TTS ë³€í™˜ í›„ ë¡œì»¬ì—ë§Œ MP3 ì €ì¥ (S3 ì—…ë¡œë“œ ì—†ìŒ)
    """
    if not text or text.strip() == "":
        raise ValueError("TTS ë³€í™˜í•  í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    # 1ï¸âƒ£ Google TTS í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    client = texttospeech.TextToSpeechClient(transport="rest")

    synthesis_input = texttospeech.SynthesisInput(text=text)

    voice_map = {
        "ì—¬ì„±": "ko-KR-Neural2-A",
        "ë‚¨ì„±": "ko-KR-Neural2-C",
    }
    name = voice_map.get(voice)
    
    voice_config = texttospeech.VoiceSelectionParams(
        language_code="ko-KR",
        name=name,
    )

    rate_map = {"ëŠë¦¼": 0.8, "ë³´í†µ": 1.0, "ë¹ ë¦„": 1.25}
    speaking_rate = rate_map.get(rate)

    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        speaking_rate=speaking_rate,
    )

    # 2ï¸âƒ£ TTS ë³€í™˜
    response = client.synthesize_speech(
        input=synthesis_input,
        voice=voice_config,
        audio_config=audio_config
    )

    if not response.audio_content:
        raise ValueError("TTS ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    # 3ï¸âƒ£ ë¡œì»¬ì—ë§Œ ì €ì¥
    local_dir = os.path.join(settings.BASE_DIR, "tts_local")
    os.makedirs(local_dir, exist_ok=True)

    base_name = text.strip().replace(" ", "")[:6] or "tts"
    gender_label = "(ì—¬ì„±)" if "Neural2-A" in voice_config.name else "(ë‚¨ì„±)"
    safe_name = f"{base_name}{gender_label}.mp3"

    # ğŸš« íŒŒì¼ëª…ì— íŒŒì¼ ì‹œìŠ¤í…œ ë¶ˆê°€ ë¬¸ì ì œê±°
    safe_name = "".join(c for c in safe_name if c.isalnum() or c in "()._")

    local_path = os.path.join(local_dir, safe_name)

    with open(local_path, "wb") as out:
        out.write(response.audio_content)

    return local_path

def time_to_seconds(hhmmss: str) -> float:
    try:
        t = datetime.strptime(hhmmss, "%H:%M:%S")
        return t.hour * 3600 + t.minute * 60 + t.second
    except ValueError:
        raise ValueError("ì‹œê°„ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (ì˜ˆ: 00:12:45)")
    
def get_duration(audio):
    
    if isinstance(audio, str):
        file_path = audio

        if not os.path.exists(file_path):
            raise ValueError(f"íŒŒì¼ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
    else:
        audio.seek(0)
        content = audio.read()
        file_path = "/tmp/_duration_temp.wav"
        with open(file_path, "wb") as f:
            f.write(content)

    filename = file_path.lower()

    if filename.endswith(".wav"):
        try:
            with wave.open(file_path, "rb") as wav_file:
                frames = wav_file.getnframes()
                rate = wav_file.getframerate()
                duration_sec = int(frames / rate)
                duration = str(timedelta(seconds=duration_sec))
                return duration_sec, duration

        except Exception as e:
            raise ValueError(f"WAV ê¸¸ì´ ê³„ì‚° ì‹¤íŒ¨: {e}")

    else:
        raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í¬ë§·ì…ë‹ˆë‹¤. (WAVë§Œ ê°€ëŠ¥)")

    # âœ… MP3 íŒŒì¼
    # try:
    #     audio.seek(0)
    #     audio_obj = File(audio)
    #     if audio_obj and hasattr(audio_obj, "info") and hasattr(audio_obj.info, "length"):
    #         rate = int(getattr(audio_obj.info, "sample_rate", 16000))
    #         channels = getattr(audio_obj.info, "channels", 1)
    #         duration_sec = round(audio_obj.info.length, 2)
    #         duration = str(timedelta(seconds=int(duration_sec)))
    #         return duration_sec, duration, rate, channels
    #     else:
    #         raise ValueError("ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê¸¸ì´ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    # except Exception as e:
    #     raise ValueError(f"ì˜¤ë””ì˜¤ ê¸¸ì´ ê³„ì‚° ì‹¤íŒ¨: {e}")

